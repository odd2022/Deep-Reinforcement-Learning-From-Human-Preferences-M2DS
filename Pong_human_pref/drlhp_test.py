if __name__ == "__main__":
    import time
    import gymnasium as gym
    from trial import HumanPreferencesEnvWrapper

    env = HumanPreferencesEnvWrapper(gym.make("CartPole-v1"), segment_length=20)

    num_episodes = 10

    for episode in range(num_episodes):
        if episode == num_episodes // 2:
            env.switch_to_predicted_reward()
            print("üöÄ Activation de la r√©compense pr√©dite par le mod√®le !")

        obs, _ = env.reset()  # Gymnasium retourne un tuple (obs, info)
        done = False
        total_reward = 0

        while not done:
            action = env.action_space.sample()  # Prendre une action al√©atoire
            obs, reward, done, info = env.step(action)
            total_reward += reward
            time.sleep(0.05)  # Pause pour mieux voir le d√©roulement

        print(f"√âpisode {episode + 1} termin√© avec un score de {total_reward}")

        # üîπ Ajout du questionnement des pr√©f√©rences APRES chaque √©pisode
        pref = env.pref_interface.query_user()
        if pref:
            print("Pr√©f√©rence re√ßue, entra√Ænement en cours...")
            s1, s2, preference = pref
            loss = env.reward_predictor.train_model(s1, s2, preference, env.optimizer, env.criterion)
            print(f"Loss: {loss}")

    print("‚úÖ Entra√Ænement termin√© !")
